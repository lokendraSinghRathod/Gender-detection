{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('C:\\\\Users\\\\Nandu\\\\Downloads\\\\names_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         index       name sex\n",
      "0            0       Mary   F\n",
      "1            1       Anna   F\n",
      "2            2       Emma   F\n",
      "3            3  Elizabeth   F\n",
      "4            4     Minnie   F\n",
      "5            5   Margaret   F\n",
      "6            6        Ida   F\n",
      "7            7      Alice   F\n",
      "8            8     Bertha   F\n",
      "9            9      Sarah   F\n",
      "10          10      Annie   F\n",
      "11          11      Clara   F\n",
      "12          12       Ella   F\n",
      "13          13   Florence   F\n",
      "14          14       Cora   F\n",
      "15          15     Martha   F\n",
      "16          16      Laura   F\n",
      "17          17     Nellie   F\n",
      "18          18      Grace   F\n",
      "19          19     Carrie   F\n",
      "20          20      Maude   F\n",
      "21          21      Mabel   F\n",
      "22          22     Bessie   F\n",
      "23          23     Jennie   F\n",
      "24          24   Gertrude   F\n",
      "25          25      Julia   F\n",
      "26          26     Hattie   F\n",
      "27          27      Edith   F\n",
      "28          28     Mattie   F\n",
      "29          29       Rose   F\n",
      "...        ...        ...  ..\n",
      "94995  1858537     Vahagn   M\n",
      "94996  1858544     Vegeta   M\n",
      "94997  1858551    Vidhaan   M\n",
      "94998  1858557    Viransh   M\n",
      "94999  1858558      Vishv   M\n",
      "95000  1858561     Waaris   M\n",
      "95001  1858575      Xaire   M\n",
      "95002  1858577    Xannder   M\n",
      "95003  1858588   Yahushua   M\n",
      "95004  1858590    Yaidden   M\n",
      "95005  1858591  Yamajesty   M\n",
      "95006  1858594     Yandry   M\n",
      "95007  1858595     Yannai   M\n",
      "95008  1858604      Yiddy   M\n",
      "95009  1858605       Yien   M\n",
      "95010  1858610   Yirmeyah   M\n",
      "95011  1858615   Yordanny   M\n",
      "95012  1858618   Yoshiyah   M\n",
      "95013  1858623      Yurik   M\n",
      "95014  1858625        Ywa   M\n",
      "95015  1858635      Zafer   M\n",
      "95016  1858639     Zaheen   M\n",
      "95017  1858652      Zarar   M\n",
      "95018  1858654     Zareon   M\n",
      "95019  1858655    Zarrien   M\n",
      "95020  1858664   Zecharya   M\n",
      "95021  1858676     Ziheng   M\n",
      "95022  1858679       Ziyu   M\n",
      "95023  1858686      Zykir   M\n",
      "95024  1858688       Zyus   M\n",
      "\n",
      "[95025 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95025 names in dataset\n"
     ]
    }
   ],
   "source": [
    "print (\"%d names in dataset\" % len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary' 'F']\n",
      " ['Anna' 'F']\n",
      " ['Emma' 'F']\n",
      " ...\n",
      " ['Ziyu' 'M']\n",
      " ['Zykir' 'M']\n",
      " ['Zyus' 'M']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "names = names.as_matrix()[:, 1:]\n",
    "print (names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first-letter': 'j', 'first2-letters': 'jo', 'first3-letters': 'joh', 'last-letter': 'n', 'last2-letters': 'hn', 'last3-letters': 'ohn'}\n"
     ]
    }
   ],
   "source": [
    "def features(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        'first-letter': name[0], # First letter\n",
    "        'first2-letters': name[0:2], # First 2 letters\n",
    "        'first3-letters': name[0:3], # First 3 letters\n",
    "        'last-letter': name[-1],\n",
    "        'last2-letters': name[-2:],\n",
    "        'last3-letters': name[-3:],\n",
    "    }\n",
    " \n",
    "print (features(\"John\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'first-letter': 'a', 'first2-letters': 'an', 'first3-letters': 'ann', 'last-letter': 'a', 'last2-letters': 'na', 'last3-letters': 'nna'}\n",
      " {'first-letter': 'h', 'first2-letters': 'ha', 'first3-letters': 'han', 'last-letter': 'h', 'last2-letters': 'ah', 'last3-letters': 'nah'}\n",
      " {'first-letter': 'p', 'first2-letters': 'pa', 'first3-letters': 'pau', 'last-letter': 'l', 'last2-letters': 'ul', 'last3-letters': 'aul'}]\n",
      "Name: Mary, features={'first-letter': 'm', 'first2-letters': 'ma', 'first3-letters': 'mar', 'last-letter': 'y', 'last2-letters': 'ry', 'last3-letters': 'ary'}, gender=F\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the features function\n",
    "features = np.vectorize(features)\n",
    "print (features([\"Anna\", \"Hannah\", \"Paul\"]))\n",
    "\n",
    "# Extract the features for the whole dataset\n",
    "X = features(names[:, 0]) # X contains the features\n",
    " \n",
    "# Get the gender column\n",
    "y = names[:, 1]           # y contains the targets\n",
    " \n",
    "# Test if we built the dataset correctly\n",
    "print (\"Name: %s, features=%s, gender=%s\" % (names[0][0], X[0], y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76020 19005 76020 19005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)\n",
    "X_train, X_test = X[:int(TRAIN_SPLIT * len(X))], X[int(TRAIN_SPLIT * len(X)):]\n",
    "y_train, y_test = y[:int(TRAIN_SPLIT * len(y))], y[int(TRAIN_SPLIT * len(y)):]\n",
    " \n",
    "# Check to see if the datasets add up\n",
    "print (len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    " \n",
    "vectorizer = DictVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    " \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(vectorizer.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n"
     ]
    }
   ],
   "source": [
    "print (clf.predict(vectorizer.transform(features([\"Ankit\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874638253091291\n"
     ]
    }
   ],
   "source": [
    "print (clf.score(vectorizer.transform(X_train), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8668771375953697\n"
     ]
    }
   ],
   "source": [
    "print (clf.score(vectorizer.transform(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
